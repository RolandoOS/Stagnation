# Part 2.1: Random forest.

# In this analysis we'll attempt to gather the most relevant meteorological variables (eulerean) that affect the concentrations of PM2.5 in the NEUS during the summer. We speculate that random forest analysis we'll give us insights into this problem. We'll sample MERRA gridpoints in the NEUS and make a point-by-point data frame.

# ----------------------------------------------------------------------

# TASK: [1] Find the conditions under which high values happen.
#		[2] Time series plot of RF model.
#		[3] Determine skill of the models.

# --- Import tools and data --------------------------------------------

import matplotlib
import pandas  as pd
import numpy   as np
import seaborn as sns
import statsmodels.api   as sm
import matplotlib.pyplot as plt
from ggplot import *
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import scale
from time import time

plt.get_backend()
plt.switch_backend('Agg')

sns.set(style="white", font="monospace")

# Directory paths:

PATH_AOD = '/Users/Rola/Documents/Science/JHU/DATA/MERRAero/'
PATH_RES = '/Users/Rola/Documents/Science/JHU/ANALYSIS/Stagnation/'

# Load the data frame generated by the program stag_random_forest_0.py

DAT=pd.read_csv(PATH_RES+'Stagnation_random_forest_matrix_neus.csv', index_col='date', parse_dates=True)

DAT['wnd_500hPa']=np.sqrt(np.power(DAT['u_500hPa'],2)+np.power(DAT['v_500hPa'],2))
DAT['wnd_2m']=np.sqrt(np.power(DAT['u_2m'],2)+np.power(DAT['v_2m'],2))
data=pd.DataFrame(DAT, columns=['wnd_500hPa','wnd_2m','hgt_500hPa','precip','temp_2m','spec_humidity','slp','AmmSO4','OC','PM25'])
data=(data-data.mean())/data.std() # scaling

dat=data.resample('d', how='mean')

dat['2006-06':'2006-08'].ix[:,7:10].plot(); sns.plt.show()

sns.pairplot(dat.ix[:,0:8], diag_kind = "kde") #takes a while (lots of data)
plt.savefig(PATH_RES+'scatter_matrix_1.png', dpi = 300)
sns.plt.show()

sns.heatmap(dat.ix[:,0:8].corr(), annot=True, square=True, cmap='BrBG', cbar_kws={"shrink": .75})
plt.savefig(PATH_RES+'scatter_matrix_corr_2.png', dpi = 200);
plt.show()
plt.clf()


dat.ix[:,0:8].corr().values

# --- Test variables with GLM ------------------------------------------

X = data.ix[:,0:7]
X['intercept'] = 1.0

Y = data['AmmSO4']

glm=sm.GLM(Y,X, family=sm.families.Gaussian()).fit()
print glm.summary()


# --- Random Forest Regressions ----------------------------------------

data['is_train'] = np.random.uniform(0, 1, len(data)) <= 0.80

train, test = data[data['is_train']==True], data[data['is_train']==False]

factors = data.columns[:7]
begin=time()
rfr = RandomForestRegressor(n_estimators=100, n_jobs=10)
y = train['AmmSO4']
rfr.fit(train[factors], y)
print time()-begin

print rfr.score(test[factors], test['AmmSO4']) # 0.661268359009

preds = rfr.predict(test[factors])
test['preds']=preds

pd.DataFrame(factors, 100*rfr.feature_importances_, columns=['% Imp'])

g=sns.jointplot('AmmSO4', 'preds', data=test, kind="kde", size=7, space=0, xlim=[-1.5,2], ylim=[-1.5,2])
x0, x1 = g.ax_joint.get_xlim()
y0, y1 = g.ax_joint.get_ylim()
lims = [max(x0, y0), min(x1, y1)]
g.ax_joint.plot(lims, lims, 'k')
plt.savefig(PATH_RES+'random_forest_skill_1.png', dpi = 200);
plt.show()
plt.clf()

plt.switch_backend('MacOSX')
test['2005'][['AmmSO4','preds']].resample('d', how='mean').plot(marker='o')
plt.savefig(PATH_RES+'random_forest_skill_2.png', dpi = 200);
plt.show()

plt.switch_backend('MacOSX')
test['2005'][['AmmSO4','spec_humidity','slp']].resample('d', how='mean').plot()
plt.savefig(PATH_RES+'random_forest_meteorology.png', dpi = 200);
plt.show()

# --- Random Forest Classifier -----------------------------------------

stag_treshold=15  #ug/m^3

df=DAT.ix[:,[0,1,2,3,4,5,6,7,8,11]]
df['is_stagnant']=0;
df.loc[df['AmmSO4'] > stag_treshold, 'is_stagnant'] = 1
# df['is_stagnant'][df['PM25']>30]=1

df['is_train'] = np.random.uniform(0, 1, len(df)) <= 0.8

train, test = df[df['is_train']==True], df[df['is_train']==False]

factors = df.columns[:9]
begin=time()
clf = RandomForestClassifier(n_estimators=1000, n_jobs=10)
y = train['is_stagnant']
clf.fit(train[factors], y)
print time()-begin

print clf.score(test[factors], test['is_stagnant']) # 0.978

preds = clf.predict(test[factors])
print pd.crosstab(test['is_stagnant'], preds, rownames=['actual'], colnames=['preds'])

#        | preds
# actual | clear  stagn
# ----------------------
# clear  | 41458    20
# stagn  |   872   214

# ----------------------------------------------------------------------

iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75
df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)
df.head()

train, test = df[df['is_train']==True], df[df['is_train']==False]

features = df.columns[:4]
clf = RandomForestClassifier(n_estimators=10, n_jobs=2)
y, _ = pd.factorize(train['species'])
clf.fit(train[features], y)

preds = iris.target_names[clf.predict(test[features])]
pd.crosstab(test['species'], preds, rownames=['actual'], colnames=['preds'])


random_forest_meteorology.png random_forest_skill_1.png random_forest_skill_2.png scatter_matrix_1.png scatter_matrix_corr_1.png scatter_matrix_corr_2.png
