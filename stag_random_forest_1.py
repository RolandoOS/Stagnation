""" Stagnation MERRA Timeseries """

# Part 2.1: Random forest.

# In this analysis we'll attempt to gather the most relevant meteorological variables (eulerean) that affect the concentrations of PM2.5 in the NEUS during the summer. We speculate that random forest analysis we'll give us insights into this problem. We'll sample MERRA gridpoints in the NEUS and make a point-by-point data frame.

# --- Import tools and data --------------------------------------------

import pandas as pd
import numpy  as np
import statsmodels.api   as sm
import matplotlib.pyplot as plt
import ggplot
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier


# Directory paths:

PATH_AOD = '/Users/Rola/Documents/Science/JHU/DATA/MERRAero/'
PATH_RES = '/Users/Rola/Documents/Science/JHU/ANALYSIS/Stagnation/'

# Load the data frame generated by the program stag_random_forest_0.py

DAT=pd.read_csv(PATH_RES+'Stagnation_random_forest_matrix_1.csv', index_col='date', parse_dates=True)

DAT[['PM25']]['2006'].resample('d', how='mean').plot(); plt.show()
DAT[['hgt_500hPa']]['2006'].resample('d', how='mean').plot(); plt.show()

# --- Test variables with GLM ------------------------------------------

DAT['PM25'].hist(bins=50); plt.show()

DAT.hist(bins=50)
plt.savefig(PATH_RES+'Fig_rand_forest_1.png', dpi=500); plt.show()

X = DAT.ix[:,0:9]
X['intercept'] = 1.0

Y = DAT['PM25']

glm=sm.GLM(Y,X, family=sm.families.Gaussian()).fit()
conf=glm.conf_int()
conf.columns = ['2.5%', '97.5%']
conf['Coeficients']=glm.params
conf=np.exp(conf)

print glm.summary()
#print glm.params[glm.pvalues<0.05][:-1]
#print glm.params[glm.params==glm.params[glm.pvalues<0.05][:-2].max()]

# ----------------------------------------------------------------------
#
#					 Generalized Linear Model Regression Results                  
#	==============================================================================
#	Dep. Variable:                   PM25   No. Observations:               214076
#	Model:                            GLM   Df Residuals:                   214066
#	Model Family:                 Poisson   Df Model:                            9
#	Link Function:                    log   Scale:                             1.0
#	Method:                          IRLS   Log-Likelihood:            -7.4218e+05
#	Date:                Mon, 27 Jul 2015   Deviance:                   5.9612e+05
#	Time:                        11:57:14   Pearson chi2:                 9.00e+05
#	No. Iterations:                   100                                         
#	=================================================================================
#						coef    std err          z      P>|z|      [95.0% Conf. Int.]
#	---------------------------------------------------------------------------------
#	u_500hPa         -0.0022      0.000    -19.637      0.000        -0.002    -0.002
#	v_500hPa         -0.0041      0.000    -36.617      0.000        -0.004    -0.004
#	hgt_500hPa        0.0025      0.000     13.037      0.000         0.002     0.003
#	precip         1353.0795     10.484    129.059      0.000      1332.531  1373.628
#	u_2m              0.0533      0.001     45.681      0.000         0.051     0.056
#	v_2m              0.0569      0.001     60.151      0.000         0.055     0.059
#	temp_2m           0.0531      0.000    162.763      0.000         0.052     0.054
#	spec_humidity    44.1407      0.410    107.607      0.000        43.337    44.945
#	slp            8.599e-05   2.35e-06     36.640      0.000      8.14e-05  9.06e-05
#	intercept       -23.9789      0.213   -112.367      0.000       -24.397   -23.561
#	=================================================================================

iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75
df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)
df.head()

train, test = df[df['is_train']==True], df[df['is_train']==False]

features = df.columns[:4]
clf = RandomForestClassifier(n_jobs=2)
y, _ = pd.factorize(train['species'])
clf.fit(train[features], y)

preds = iris.target_names[clf.predict(test[features])]
pd.crosstab(test['species'], preds, rownames=['actual'], colnames=['preds'])

